{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Kaggle Competition Site - Kenyan Food Image Classification\n"]},{"cell_type":"markdown","metadata":{},"source":["This competition is about classification of Kenyan food images.\n","The dataset consists of 8,174 images in 13 Kenyan food type classes. \n","\n","The details of the competition:\n","https://www.kaggle.com/c/opencv-pytorch-dl-course-classification"]},{"cell_type":"markdown","metadata":{},"source":["## Summary"]},{"cell_type":"markdown","metadata":{},"source":["Trained 50 epochs using modified ResNet152 network\n","\n","Modified the original single fully connected layer to 2 fully connected layers with 2 dropout layers\n","\n","Unfreezed Layer 4 in the original ResNet152 network and the 2 newly added fully connected layers. Freezed all other layers (Transfer Learning)\n","\n","Used the model weights at Epoch 31 (Early Stopping)\n","\n","Training Accuracy:   81.9%\n","\n","Validation Accuracy: 78.3%\n","\n","Test Accuracy:       77.5%\n"]},{"cell_type":"markdown","metadata":{},"source":["## TensorBoard Dev Scalars Log Link "]},{"cell_type":"markdown","metadata":{},"source":["https://tensorboard.dev/experiment/0NHYnHGqS2OuOouVrxKejw/"]},{"cell_type":"markdown","metadata":{},"source":["## Competition Leaderboard"]},{"cell_type":"markdown","metadata":{},"source":["https://www.kaggle.com/c/opencv-pytorch-dl-course-classification/leaderboard"]},{"cell_type":"markdown","metadata":{},"source":["## Code"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:04:04.599576Z","iopub.status.busy":"2021-12-15T00:04:04.599263Z","iopub.status.idle":"2021-12-15T00:04:57.890094Z","shell.execute_reply":"2021-12-15T00:04:57.888145Z","shell.execute_reply.started":"2021-12-15T00:04:04.599493Z"},"trusted":true},"outputs":[],"source":["!rm -rf /kaggle/working/trainer\n","!mkdir -p /kaggle/working/images\n","!cp /kaggle/input/opencv-pytorch-dl-course-classification/images/images/* /kaggle/working/images\n","!cp /kaggle/input/opencv-pytorch-dl-course-classification/*.csv /kaggle/working\n","!mkdir -p /kaggle/working/dataset\n","!cd /kaggle/working"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:04:57.894252Z","iopub.status.busy":"2021-12-15T00:04:57.893881Z","iopub.status.idle":"2021-12-15T00:05:00.914328Z","shell.execute_reply":"2021-12-15T00:05:00.913636Z","shell.execute_reply.started":"2021-12-15T00:04:57.894206Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","import torch\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils import data\n","from operator import itemgetter\n","from torchvision import transforms, models\n","from torch.utils.data import Dataset, DataLoader\n","\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","import random\n","import datetime\n","from typing import Callable, Iterable\n","import torch.nn.functional as F\n","from dataclasses import dataclass\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import functional as TF\n","from torch.utils.tensorboard import SummaryWriter\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:00.916268Z","iopub.status.busy":"2021-12-15T00:05:00.915976Z","iopub.status.idle":"2021-12-15T00:05:00.921986Z","shell.execute_reply":"2021-12-15T00:05:00.921079Z","shell.execute_reply.started":"2021-12-15T00:05:00.916235Z"},"trusted":true},"outputs":[],"source":["def seed_everything(sys_config):\n","    random.seed(sys_config.seed)\n","    np.random.seed(sys_config.seed)\n","    torch.manual_seed(sys_config.seed)\n","    torch.backends.cudnn.deterministic = sys_config.cudnn_deterministic\n","    torch.backends.cudnn.benchmark = sys_config.cudnn_benchmark_enabled"]},{"cell_type":"markdown","metadata":{},"source":["### Define System and Training Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:00.924255Z","iopub.status.busy":"2021-12-15T00:05:00.924005Z","iopub.status.idle":"2021-12-15T00:05:00.937373Z","shell.execute_reply":"2021-12-15T00:05:00.936657Z","shell.execute_reply.started":"2021-12-15T00:05:00.924227Z"},"trusted":true},"outputs":[],"source":["@dataclass\n","class SystemConfiguration:\n","    '''\n","    Describes the common system setting needed for reproducible training\n","    '''\n","    seed: int = 42                          # seed number to set the state of all random number generators\n","    cudnn_benchmark_enabled: bool = True    # enable CuDNN benchmark for the sake of performance\n","    cudnn_deterministic: bool = True        # make cudnn deterministic (reproducible training)\n","\n","@dataclass\n","class TrainerConfig:\n","    \"\"\"\n","    Describes configuration for the training process\n","    \"\"\"\n","    batch_size: int = 16\n","    resnet_model_name = \"resnet152\"        # change network structure here\n","    \n","    num_epochs: int = 50\n","    learning_rate: float = 0.00001\n","    \n","    data_root: str = r\"/kaggle/working\"\n","    root_log_dir: str = r\"runs\"\n","    root_checkpoint_dir: str = r\"checkpoints\"\n","    num_workers: int = max(2, os.cpu_count() - 2)\n","    device: str = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","    save_freq: str = \"each\"                 # \"best\" OR \"each\""]},{"cell_type":"markdown","metadata":{},"source":["### Split Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:00.939662Z","iopub.status.busy":"2021-12-15T00:05:00.939052Z","iopub.status.idle":"2021-12-15T00:05:00.958525Z","shell.execute_reply":"2021-12-15T00:05:00.95743Z","shell.execute_reply.started":"2021-12-15T00:05:00.939616Z"},"trusted":true},"outputs":[],"source":["def generateDatasetStructure(class_names, data_root, train_ratio=0.75):\n","    # write class labels to file\n","    dataset_dir = os.path.join(data_root, 'dataset')\n","    os.makedirs(dataset_dir, exist_ok=True)\n","    file = open(os.path.join(dataset_dir, 'class_names.txt'), 'w')\n","    for class_name in class_names:\n","        file.write(class_name + '\\n')\n","    file.close()\n","\n","    # creating directories\n","    training_dir = os.path.join(data_root, 'dataset/training')\n","    validation_dir = os.path.join(data_root, 'dataset/validation')\n","    os.makedirs(training_dir, exist_ok=True)\n","    os.makedirs(validation_dir, exist_ok=True)\n","    for class_name in class_names:\n","        os.makedirs(os.path.join(training_dir, class_name), exist_ok=True)\n","        os.makedirs(os.path.join(validation_dir, class_name), exist_ok=True)\n","\n","    # read image names from 'train.csv' into a hashmap: class_name -> image_names\n","    train_csv_path = os.path.join(data_root, 'train.csv')\n","    raw_data_info = pd.read_csv(train_csv_path, engine='python', dtype={0:str, 1:str})\n","    class_to_img_path = {class_name:[] for class_name in class_names}\n","\n","    for filename, class_name in raw_data_info.values:\n","        full_file_path = os.path.join(data_root, 'images', filename + '.jpg')\n","        class_to_img_path[class_name].append(full_file_path)\n","\n","    # split images into training/validation and put images in each class folders \n","    for class_name in class_to_img_path:\n","        data_len_single_class = len(class_to_img_path[class_name])\n","        training_src_paths = class_to_img_path[class_name][:int(train_ratio * data_len_single_class)]\n","        validation_src_paths = class_to_img_path[class_name][int(train_ratio * data_len_single_class):]\n","        training_dst_path = os.path.join(training_dir, class_name)\n","        validation_dst_path = os.path.join(validation_dir, class_name)\n","        for path in training_src_paths:\n","            shutil.copy(path, training_dst_path)\n","        for path in validation_src_paths:\n","            shutil.copy(path, validation_dst_path)\n","            \n","    return class_to_img_path"]},{"cell_type":"markdown","metadata":{},"source":["### Transforms and Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:00.960254Z","iopub.status.busy":"2021-12-15T00:05:00.959894Z","iopub.status.idle":"2021-12-15T00:05:00.975533Z","shell.execute_reply":"2021-12-15T00:05:00.974926Z","shell.execute_reply.started":"2021-12-15T00:05:00.960222Z"},"trusted":true},"outputs":[],"source":["def image_preprocess_transforms():\n","    preprocess = transforms.Compose([\n","    transforms.Resize(350),\n","    transforms.CenterCrop(300),\n","    transforms.ToTensor()\n","    ])\n","    \n","    return preprocess\n","\n","def image_common_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n","    preprocess = image_preprocess_transforms()\n","    \n","    common_transforms = transforms.Compose([\n","        preprocess,\n","        transforms.Normalize(mean, std)\n","    ])\n","    \n","    return common_transforms\n","\n","def data_augmentation_preprocess(common_transforms):\n","    \n","    data_augmented_transforms = transforms.Compose([\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.RandomRotation(20, fill=(0,0,0)),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","        common_transforms\n","    ])\n","    \n","    return data_augmented_transforms"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate Image mean and std"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:00.977617Z","iopub.status.busy":"2021-12-15T00:05:00.976812Z","iopub.status.idle":"2021-12-15T00:05:00.992601Z","shell.execute_reply":"2021-12-15T00:05:00.991714Z","shell.execute_reply.started":"2021-12-15T00:05:00.97757Z"},"trusted":true},"outputs":[],"source":["def get_mean_std(data_root, batch_size=16, num_workers=4):\n","    preprocess = image_preprocess_transforms()\n","    \n","    training_set_with_basic_transforms = ImageFolder(\n","        os.path.join(data_root, \"dataset\", \"training\"), transform=preprocess\n","    )\n","\n","    loader = torch.utils.data.DataLoader(\n","        training_set_with_basic_transforms,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=num_workers,\n","    )\n","\n","    mean = 0.0\n","    std = 0.0\n","\n","    for images, _ in loader:\n","        batch_samples = images.size(0)\n","        images = images.view(batch_samples, images.size(1), -1)\n","        mean += images.mean(2).sum(0)\n","        std += images.std(2).sum(0)\n","    mean /= len(loader.dataset)\n","    std /= len(loader.dataset)\n","\n","    print(\"mean: {}, std: {}\".format(mean, std))\n","\n","    return mean, std"]},{"cell_type":"markdown","metadata":{},"source":["### Create Dataset and Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:00.994814Z","iopub.status.busy":"2021-12-15T00:05:00.994149Z","iopub.status.idle":"2021-12-15T00:05:01.009785Z","shell.execute_reply":"2021-12-15T00:05:01.008901Z","shell.execute_reply.started":"2021-12-15T00:05:00.994766Z"},"trusted":true},"outputs":[],"source":["def get_data(config, data_augmentation=False):\n","\n","    mean, std = get_mean_std(config.data_root, batch_size=config.batch_size, num_workers=config.num_workers)\n","    common_transforms = image_common_transforms(mean, std)\n","\n","    # data augmentation implementation\n","    if data_augmentation:\n","        train_transforms = transforms.Compose(\n","            [\n","                data_augmentation_preprocess(common_transforms),\n","                transforms.RandomErasing(),\n","            ]\n","        )\n","    else:\n","        train_transforms = common_transforms\n","        \n","    training_set = ImageFolder(\n","        os.path.join(config.data_root, \"dataset\", \"training\"), transform=train_transforms\n","    )\n","\n","    validation_set = ImageFolder(\n","        os.path.join(config.data_root, \"dataset\", \"validation\"), transform=common_transforms\n","    )\n","\n","    pin = True if config.device == torch.device(\"cuda\") else False\n","    \n","    training_loader = torch.utils.data.DataLoader(\n","        training_set,\n","        batch_size=config.batch_size,\n","        shuffle=True,\n","        num_workers=config.num_workers,\n","        pin_memory=pin,\n","    )\n","    \n","    validation_loader = torch.utils.data.DataLoader(\n","        validation_set,\n","        batch_size=config.batch_size,\n","        shuffle=False,\n","        num_workers=config.num_workers,\n","        pin_memory=pin,\n","    )\n","\n","    return training_loader, validation_loader"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet Model Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:01.011369Z","iopub.status.busy":"2021-12-15T00:05:01.011118Z","iopub.status.idle":"2021-12-15T00:05:01.026802Z","shell.execute_reply":"2021-12-15T00:05:01.026159Z","shell.execute_reply.started":"2021-12-15T00:05:01.011337Z"},"trusted":true},"outputs":[],"source":["def pretrained_resnet(model_name, transfer_learning=True, num_class=13):          # adjust the number of classes here\n","    if model_name == \"resnet18\":\n","        resnet = models.resnet18(pretrained=True)\n","    elif model_name == \"resnet50\":\n","        resnet = models.resnet50(pretrained=True)\n","    elif model_name == \"resnet101\":\n","        resnet = models.resnet101(pretrained=True)\n","    elif model_name == \"resnet152\":\n","        resnet = models.resnet152(pretrained=True)\n","    elif model_name == \"resnext50_32x4d\":\n","        resnet = models.resnext50_32x4d(pretrained=True)\n","    \n","    if transfer_learning:\n","        for param in resnet.parameters():\n","            param.requires_grad = False\n","\n","        resnet.layer4.requires_grad_(True)          \n","    \n","    last_layer_in = resnet.fc.in_features\n","    \n","    resnet.fc = nn.Sequential(\n","        nn.Dropout(0.5),\n","        nn.Linear(last_layer_in, 256),\n","        nn.Dropout(0.5),\n","        nn.Linear(256, num_class)\n","    )\n","    \n","    return resnet"]},{"cell_type":"markdown","metadata":{},"source":["### Training/Validation Utility functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:01.029367Z","iopub.status.busy":"2021-12-15T00:05:01.028994Z","iopub.status.idle":"2021-12-15T00:05:01.044052Z","shell.execute_reply":"2021-12-15T00:05:01.043304Z","shell.execute_reply.started":"2021-12-15T00:05:01.029334Z"},"trusted":true},"outputs":[],"source":["def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:01.045367Z","iopub.status.busy":"2021-12-15T00:05:01.045094Z","iopub.status.idle":"2021-12-15T00:05:01.061538Z","shell.execute_reply":"2021-12-15T00:05:01.06093Z","shell.execute_reply.started":"2021-12-15T00:05:01.045339Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(\n","    model,\n","    optimizer,\n","    device,\n","    epoch,\n","    num_epochs,\n","    *,\n","    loss_fn,\n","    dataloader,\n","    writer=None,\n","    lr_scheduler=None\n","):\n","    avg_train_acc = 0.0\n","    avg_train_loss = 0.0\n","    p_avg_train_loss = 0.0\n","    p_avg_train_acc = 0.0\n","\n","    prefix = f\"{epoch+1:03}/{num_epochs:03}\"\n","    length_loader = len(dataloader)\n","    iteration = length_loader * epoch\n","\n","    for idx, batch in enumerate(dataloader, 1):\n","        data = batch[0].to(device)\n","        target = batch[1].to(device)\n","\n","        output = model(data)\n","\n","        batch_loss = loss_fn(output, target)\n","\n","        optimizer.zero_grad()\n","        batch_loss.backward()\n","        optimizer.step()\n","        \n","        batch_acc = accuracy(output.detach(), target.detach()).item()\n","\n","        if lr_scheduler:\n","            lr_scheduler.step()\n","        batch_loss = batch_loss.detach().item()\n","\n","        # calculate running average\n","        avg_train_loss = (avg_train_loss * (idx - 1) + batch_loss) / idx\n","        avg_train_acc = (avg_train_acc * (idx - 1) + batch_acc) / idx\n","\n","        p_avg_train_loss = round(avg_train_loss, 3)\n","        p_avg_train_acc = round(avg_train_acc, 3)\n","\n","        writer.add_scalar(\"Train/batch_loss\", batch_loss, global_step=iteration + idx)\n","        writer.add_scalar(\"Train/batch_acc\", batch_acc, global_step=iteration + idx)\n","\n","        status = f\"\\rEpoch: {prefix} Iteration: {idx:03}/{length_loader:03} [Train] Accuracy: {p_avg_train_acc} Loss: {p_avg_train_loss} batch_acc: {round(batch_acc, 3)}  batch_loss: {round(batch_loss, 3)} LR: {optimizer.param_groups[0]['lr']}\"\n","        print(status)\n","\n","    writer.add_scalar(\"Train/Loss\", p_avg_train_loss, global_step=epoch)\n","    writer.add_scalar(\"Train/Acc\", p_avg_train_acc, global_step=epoch)\n","\n","    return p_avg_train_acc, p_avg_train_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:01.063353Z","iopub.status.busy":"2021-12-15T00:05:01.062712Z","iopub.status.idle":"2021-12-15T00:05:01.079012Z","shell.execute_reply":"2021-12-15T00:05:01.078236Z","shell.execute_reply.started":"2021-12-15T00:05:01.063306Z"},"trusted":true},"outputs":[],"source":["def validation_epoch(\n","    model,\n","    device,\n","    epoch,\n","    num_epochs,\n","    *,\n","    loss_fn,\n","    dataloader,\n","    writer=None,\n","):\n","\n","    avg_valid_acc = 0.0\n","    avg_valid_loss = 0.0\n","\n","    p_avg_valid_loss = 0.0\n","    p_avg_valid_acc = 0.0\n","\n","    prefix = f\"{epoch+1:03}/{num_epochs:03}\"\n","    length_loader = len(dataloader)\n","    iteration = length_loader * epoch\n","\n","    for idx, batch in enumerate(dataloader, 1):\n","        data = batch[0].to(device)\n","        target = batch[1].to(device)\n","\n","        with torch.no_grad():\n","            output = model(data)\n","\n","        batch_loss = loss_fn(output, target).detach().item()\n","        batch_acc = accuracy(output.detach(), target.detach()).item()\n","\n","        # calculate running average\n","        avg_valid_loss = (avg_valid_loss * (idx - 1) + batch_loss) / idx\n","        avg_valid_acc = (avg_valid_acc * (idx - 1) + batch_acc) / idx\n","\n","        p_avg_valid_loss = round(avg_valid_loss, 3)\n","        p_avg_valid_acc = round(avg_valid_acc, 3)\n","\n","        status = f\"\\rEpoch: {prefix} Iteration: {idx:03}/{length_loader:03} [Valid] Accuracy: {p_avg_valid_acc} Loss: {p_avg_valid_loss} batch_acc: {round(batch_acc, 3)}  batch_loss: {round(batch_loss, 3)}\"\n","        print(status)\n","        gc.collect()\n","\n","    writer.add_scalar(\"Valid/Loss\", p_avg_valid_loss, global_step=epoch)\n","    writer.add_scalar(\"Valid/Acc\", p_avg_valid_acc, global_step=epoch)\n","\n","    return p_avg_valid_acc, p_avg_valid_loss"]},{"cell_type":"markdown","metadata":{},"source":["### Training/Validation Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:05:01.080664Z","iopub.status.busy":"2021-12-15T00:05:01.080399Z","iopub.status.idle":"2021-12-15T00:06:26.61687Z","shell.execute_reply":"2021-12-15T00:06:26.614896Z","shell.execute_reply.started":"2021-12-15T00:05:01.080632Z"},"trusted":true},"outputs":[],"source":["class_names = [\n","        \"bhaji\",\n","        \"chapati\",\n","        \"nyamachoma\",\n","        \"mandazi\",\n","        \"masalachips\",\n","        \"kachumbari\",\n","        \"ugali\",\n","        \"pilau\",\n","        \"matoke\",\n","        \"githeri\",\n","        \"mukimo\",\n","        \"sukumawiki\",\n","        \"kukuchoma\",\n","    ]\n","\n","augmentation = True\n","\n","seed_everything(SystemConfiguration())\n","\n","config = TrainerConfig()\n","\n","\n","generateDatasetStructure(class_names, config.data_root)\n","\n","train_loader, val_loader = get_data(config, data_augmentation=augmentation)\n","\n","model = pretrained_resnet(model_name=config.resnet_model_name, transfer_learning=True) # True: only unfreeze certain layers\n","                                                                                       # False: unfreeze all layers\n","model.to(config.device)\n","\n","optimizer = torch.optim.Adam(\n","    model.parameters(), lr=config.learning_rate, amsgrad=True, weight_decay=1e-5\n",")\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","lr_scheduler = None"]},{"cell_type":"markdown","metadata":{},"source":["### Tensorboard Log Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:06:26.618562Z","iopub.status.busy":"2021-12-15T00:06:26.618304Z","iopub.status.idle":"2021-12-15T00:06:26.62945Z","shell.execute_reply":"2021-12-15T00:06:26.628659Z","shell.execute_reply.started":"2021-12-15T00:06:26.618529Z"},"trusted":true},"outputs":[],"source":["version_number = 0\n","\n","os.makedirs(config.root_log_dir, exist_ok=True)\n","os.makedirs(config.root_checkpoint_dir, exist_ok=True)\n","\n","folders = os.listdir(config.root_log_dir)\n","\n","if len(folders):\n","    last_version_number = int(sorted(folders)[-1].replace(\"version_\", \"\"))\n","    version_number = last_version_number + 1\n","    \n","\n","config.log_dir = os.path.join(config.root_log_dir, f\"version_{version_number}\")\n","config.checkpoint_dir = os.path.join(config.root_checkpoint_dir, f\"version_{version_number}\")\n","\n","os.makedirs(config.log_dir, exist_ok=True)\n","os.makedirs(config.checkpoint_dir, exist_ok=True)\n","\n","print(f\"Logging at: {config.log_dir}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Main Function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-15T00:06:26.631485Z","iopub.status.busy":"2021-12-15T00:06:26.63095Z","iopub.status.idle":"2021-12-15T00:08:17.443973Z","shell.execute_reply":"2021-12-15T00:08:17.442395Z","shell.execute_reply.started":"2021-12-15T00:06:26.63145Z"},"trusted":true},"outputs":[],"source":["summary_writer = SummaryWriter(log_dir=config.log_dir)\n","\n","best_val_acc = 0.0\n","best_epoch = 0\n","\n","for epoch in range(config.num_epochs):\n","    model.train()\n","    train_acc, train_loss = train_one_epoch(\n","        model,\n","        optimizer,\n","        config.device,\n","        epoch,\n","        config.num_epochs,\n","        loss_fn=loss_fn,\n","        dataloader=train_loader,\n","        writer=summary_writer,\n","        lr_scheduler=lr_scheduler\n","    )\n","    print()\n","\n","    model.eval()\n","    valid_acc, valid_loss = validation_epoch(\n","        model,\n","        config.device,\n","        epoch,\n","        config.num_epochs,\n","        loss_fn=loss_fn,\n","        dataloader=val_loader,\n","        writer=summary_writer,\n","    )\n","    print()\n","\n","    # save model weights based on validation accuracy\n","    if config.save_freq == \"best\":\n","        if valid_acc > best_val_acc:\n","            print(\"Saving Model Weights.\")\n","            best_val_acc = valid_acc\n","            best_epoch = epoch\n","            torch.save(\n","                model.state_dict(),\n","                os.path.join(config.checkpoint_dir, \"best_model_\") + str(datetime.datetime.now().strftime(\"%Y-%m-%d-%H_%M_%S\"))\n","            )\n","    elif config.save_freq == \"each\":\n","        torch.save(\n","            model.state_dict(),\n","            os.path.join(\n","                config.checkpoint_dir, f\"model_epoch-{epoch:03}-valid_acc-{valid_acc}_\"\n","            ) + str(datetime.datetime.now().strftime(\"%Y-%m-%d-%H_%M_%S\"))\n","        )\n","        \n","summary_writer.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
